{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import flammkuchen as fl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 1.5\n",
    "dt_imaging = 1/fps\n",
    "data_root = Path(r\"C:\\Users\\vilim\\analysis\\lsmlsda_data\\whole_brain\")\n",
    "traces = fl.load(str(data_root / \"traces_better_deconvolved.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_imaging = traces.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data (so that each trace has a mean 0 and variance 1) and plot all traces together as a heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part we will correlate the individual traces (original traces, not the ones averaged over trials) with sensory and motor regressors.\n",
    "# To do so, fist load the behavioural log and stimulus log\n",
    "stimulus_log = fl.load(data_root / \"stimulus_log.h5\")\n",
    "behavior_log = fl.load(data_root / \"behavior_log.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the regressors\n",
    "### Motor regressor\n",
    "The motor regressor we sould like to have will be a general measure of the fish swimming power. Such regressor can be based on the standart deviation (SD) of the tail angle during the experiment. \n",
    "The behaviour of the fish was recorded and saved in the file \"behavioural_log\". In this DataFrame you will see the diffeent angles of the segments of the fish tail, as well as the variable \"tail_sum\". The motor regressor should be a moving SD of tail_sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the motor regressor \n",
    "\n",
    "tail_sum = behavior_log['tail_sum'].values\n",
    "\n",
    "dt_beh = np.mean(np.diff(behavior_log.t[100:200]))\n",
    "vig_win = 2/1.5\n",
    "n_vig = int(vig_win/dt_beh)\n",
    "vigor = interp1d(behavior_log.t, behavior_log.tail_sum.rolling(n_vig,  min_periods=2).std(),\n",
    "                 fill_value=0.0, bounds_error=False)(t_imaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensory regressors\n",
    "Creating two regressors for the stimulus (stimulus speed).\n",
    "From the stimulu_log, get the variable \"gain_kag_cl1D_vel\". This is the velocity of the moving gratings. We will use this trace to create two regressors - one for positive velocity and one for negative velocity. Use the interpolation me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we resample the stimulation data so that it is equaly spaced in time, at 200 times the imaging frame rate (another method is the one demonstrated above for vigor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_fact = 200\n",
    "n_t_imaging = traces.shape[1]\n",
    "t_imaging_int = np.arange(n_t_imaging*int_fact)*dt_imaging/int_fact\n",
    "\n",
    "vel_int = interp1d(stimulus_log.t, stimulus_log[\"gain_lag_cl1D_vel\"], bounds_error=False, fill_value=0)(t_imaging_int)\n",
    "\n",
    "velocity = signal.decimate(vel_int, int_fact, ftype=\"fir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating the traces with the regressors\n",
    "At this point you will correlate each calcium trace with the three regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the regressors\n",
    "\n",
    "# Correlate traces with the regressors\n",
    "# Create a scatter plot of the correlation values\n",
    "# put the regression results in a dataframe for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the best fitted neuron for each of the regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trial-averaged traces. Each trial is 180 seconds. This will show a cleaner stimulus-related response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 9\n",
    "trial_duration = 180.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction and clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract principal components of the average response.components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 3 PCs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the variance explained by each component and try to establish how many components you need to explain everything that is not noise. Extra credit: do cross validated PCA (fit the PCs on average traces of some trials, and check how many components you need to explain other trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you interpret the principal components in terms of stimulus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the neural activity of the whole brain as a phase-space plot (extra credit: encode time or stimulus value in the color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use K means clustering to classify neurons by principal component loading (using all components that are not noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the neurons in the space of principal component loading coefficients (for PC1 and PC2) and color them by cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the clusters showing discrete response classes? What are the assumptions of K-Means and does this datasat satisfy it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters in anatomical space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(in the readme now there is a link to the coords file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = fl.load(str(data_root / \"coords.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.6\n",
    "dy = 0.6\n",
    "dz = 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "ax[0,0].scatter(coords[:,1]*dx, coords[:,2]*dy, s=0.1)\n",
    "ax[0,0].set_aspect(1)\n",
    "ax[0,0].set_xticklabels('')\n",
    "\n",
    "ax[1,0].scatter(coords[:,1]*dx, coords[:,0]*dz, s=0.1)\n",
    "ax[1,0].set_aspect(1)\n",
    "\n",
    "ax[0,1].scatter(coords[:,0]*dz, coords[:,2]*dy, s=0.1)\n",
    "ax[0,1].set_aspect(1)\n",
    "ax[0,1].set_yticklabels('')\n",
    "ax[1,1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, color the cells according to principal component loading or cluster assignement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the velcity from the traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the velocity and the traces into a traning and test set. Choose carefully so that most conditions are well represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_test = \n",
    "traces_train = \n",
    "\n",
    "vel_test = \n",
    "vel_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use methods from scikit-learn, starting with sklearn.linear_model.LinearRegression (or write your own linear regression!), use the fit and predict methods to decode velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. for a linear model:\n",
    "    $$v(t) = \\Sigma_{i}^{n\\_neurons}w_i a_i(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decoded velocity vs the real velocity, in time and as a scatter plot. Which regions of the stimulus space are decoded best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit \n",
    "* try to determine how many cells you need to decode the velocity. Which cells are the most important ones, if there are such?\n",
    "* do nonlinear decoding methods (e.g. neural networks, also available with the same interface in scikit-learn) improve the decoding?\n",
    "* try to decode behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
